{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 모델 구현하기\n",
    "\n",
    "MNIST 데이터를 CNN으로 학습시키는 모델!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-85e32eec8b2e>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\soual\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전까지의 모델들은 입력값을 28X28 = 784로 차원 하나로 구성해왔음 but CNN에서는 2차원 평면으로 구성! (28X28 그대로 구현)\n",
    "\n",
    "X의 첫 번째 차원 : None = 입력 데이터의 갯수\n",
    "\n",
    "X의 마지막 차원 : 1 = 특징의 갯수! -> 회색조 이미지!(색상 1개) \n",
    "\n",
    "출력값인 10개 분류 & dropout을 위한 placeholder 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev = 0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "L1 = tf.nn.relu(L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 첫 번째 CNN 계층 구성\n",
    "\n",
    "1. 3X3 크기의 filter를 가진 convolutional 계층을 만듦\n",
    "\n",
    "2. filter에 사용할 weight 와 tensorflow가 제공하는 tf.nn.conv2d 함수 사용\n",
    "\n",
    "위의 코드는 입력층 X와 첫 번째 계층의 weight W1을 갖고 (첫 번째 줄)\n",
    "\n",
    "오른쪽과 아래쪽으로 한 칸씩 움직이는 32개의 filter를 가진 convolution 계층을 만듦 (두 번째 줄)\n",
    "\n",
    "이때, padding = 'SAME'은 filter sliding 시 이미지의 외각에서 한 칸 밖으로 움직이는 옵션! -> 이미지의 테두리까지 더 정확하게 평가 가능 (padding을 사용하여 크기가 그대로!)\n",
    "\n",
    "첫번째 layer의 size가 nXn -> 두번째 layer의 size = n-f+1 <- without pooling\n",
    "\n",
    "첫번째 layer의 size가 nXn -> 두번째 layer의 size = n+2p-f+1 <- with pooling\n",
    "\n",
    "same pooling을 하게 되면 p = (f-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 pooling 계층을 만듦\n",
    "\n",
    "앞서 만든 convolution 계층을 입력층으로 사용 -> filter 크기를 2X2로 하는 pooling 계층을 만듦 \n",
    "\n",
    "strides = [1,2,2,1] : sliding 시 두 칸 씩 움직인다는 옵션! \n",
    "\n",
    "convolution layer의 size가 nH X nW X nC -> pooling layer의 size = ((nH-f)/s + 1) X ((nW-f)/s + 1) X nC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1,1,1,1], padding = \"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 두 번째 계층 구성\n",
    "\n",
    "W2의 변수 구성 : [3,3,32,64] \n",
    "\n",
    "-> 32 : 앞 층의 filter 갯수! => 출력층의 갯수 / 첫 번째 convolution 계층이 찾아낸 이미지의 특징 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([7*7*64, 256], stddev = 0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 세 번째 계층 구성\n",
    "\n",
    "추출한 feature들을 이용해 10개의 분류를 만들어 내는 계층 구성!\n",
    "\n",
    "10개의 분류는 1차원 배열 -> 차원을 줄이는 단계를 거쳐야 함! (직전의 pooling 계층 크기 : 7X7X64 -> reshape => 7X7X64크기의 1차원 계층으로 만듦 \n",
    "\n",
    "##### L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "L2의 feature들을 7X7X64의 1차원 배열로 만들어줌 -> L3 = (1,7X7X64)\n",
    "\n",
    "##### L3 = tf.matmul(L3, W3)\n",
    "\n",
    "배열 전체를 최종 출력값의 중간 단계인 256개의 뉴런으로 연결하는 신경망 만듦\n",
    "\n",
    "L3 X W3 = (1,7X7X64) X (7X7X64,256) = (1,256)\n",
    "\n",
    "##### L3 = tf.nn.relu(L3)\n",
    "\n",
    "relu! \n",
    "\n",
    "-> **fully connected layer** : 인접한 계층의 모든 뉴런과 상호 연결된 계층\n",
    "\n",
    "##### L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "overfitting 막기 위해 dropout 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256,10], stddev = 0.01))\n",
    "model = tf.matmul(L3,W4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네 번째 계층 구성\n",
    "\n",
    "L3의 출력값 256개를 받아 최종 출력값인 0~9 label을 갖는 10개의 출력값을 만든다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "#optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost function과 AdamOptimizer를 사용한 최적화 함수를 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1) # model에 입력값을 전달하기 위해 데이터를 28X28 형태로 재구성해야함!\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch: ', '%04d' % (epoch+1), 'Avg. cost = ', '{:.3f}'.format(total_cost/total_batch))\n",
    "    \n",
    "print('최적화 완료!')\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: ', sess.run(accuracy, feed_dict = {X: mnist.test.images.reshape(-1,28,28,1), Y: mnist.test.labels, keep_prob : 1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
