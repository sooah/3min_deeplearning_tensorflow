{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 GAN 기본 모델 구현하기\n",
    "\n",
    "GAN(Generative Adversarial Network) : autoencoder와 같이 결과물을 생성하는 생성 모델\n",
    "\n",
    "- adversarial한 두 신경망을 경쟁시켜가며 결과물 생성 방법을 학습\n",
    "\n",
    "1. 실제 이미지를 구조 Discriminator에게 이 이미지가 진짜 임을 판단하게 함(학습시킨다고 생각)\n",
    "\n",
    "2. Generator를 통해 noise(random vector)로 부터 임의의 이미지를 만듦\n",
    "\n",
    "3. 만들어진 이미지를 다시 Discriminator를 통해 진짜 이미지인지 판단하게 함\n",
    "\n",
    "-> **Generator는 Discriminator를 속여 진짜처럼 보이게 하고, Discriminator는 generator가 만든 이미지를 최대한 가짜라고 구분하도록 훈련!**\n",
    "\n",
    "=> 경쟁을 통해 Generator는 실제 이미지와 상당히 비슷한 이미지 생성 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot = True)\n",
    "\n",
    "my_path = os.path.abspath('C:\\\\Users\\\\soual\\\\3Mdeeplearning\\\\9장 딥러닝의 미래 GAN\\\\samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter 설정\n",
    "\n",
    "n_noise : generator의 input으로 사용할 vector size! (latent vector)\n",
    "\n",
    "-> random noise를 입력하여 이 noise로 부터 손글씨 이미지를 무작위로 생성하도록!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN 역시 unsupervised learning! -> Y 사용 안함\n",
    "\n",
    "Discriminator에 넣을 이미지 : 실제 이미지 & Generator가 생성한 가짜 이미지\n",
    "\n",
    "가자 이미지 : noise 에서 생성 => noise를 입력할 placeholder Z 추가!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev = 0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev = 0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator 신경망에 사용할 변수 설정\n",
    "\n",
    "W1, b1 : hidden layer로 출력하기 위한 변수\n",
    "\n",
    "W2, b2 : output layer에 사용할 변수 -> W2에 사용할 변수 크기 = 28X28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev = 0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev = 0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator 신경망에 사용할 변수 설정\n",
    "\n",
    "hidden layer는 generator와 동일하게 구성\n",
    "\n",
    "Discriminator : 진짜와 얼마나 가까운가를 판단하는 값으로 0~1 사이 값 출력 => scalar 값 1개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, G_W2) + G_b2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator NN \n",
    "\n",
    "무작위로 생성한 noise를 받아 weight와 bias를 반영하여 hidden layer를 만듦\n",
    "\n",
    "hidden layer에서 실제 image와 같은 크기의 결과값을 출력!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator NN\n",
    "\n",
    "같은 구성! but 0~1사이 scalar 값 하나 출력하기 위해 활성화 함수로 sigmoid 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size = (batch_size, n_noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random noise를 만들어주는 유틸리티 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)\n",
    "D_gene = discriminator(G)\n",
    "D_real = discriminator(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노이즈 Z를 이용해 가짜 이미지를 만들 generator G를 만듦\n",
    "\n",
    "이 G가 만든 가짜 이미지와 진짜 이미지 X를 각각 Discriminator에 넣어 입력한 이미지가 진짜인지 판별!\n",
    "\n",
    "-> 잘 학습시킬 경우 생성자가 실제에 가까운 이미지를 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function 설정\n",
    "\n",
    "2개 필요! \n",
    "\n",
    "1. Generator가 만든 이미지를 Discriminator가 가짜라고 판단하도록 하는 cost (경찰이 학습해야!)\n",
    "\n",
    "-> D_real은 1에 가까워야 하며(진짜라고 판별), D_gene은 0에 가까워야 함(가짜라고 판별)\n",
    "\n",
    "-> D_real과 1-D_gene 을 더한 값을 손실값으로! -> 이를 최대화하면 경찰(Discriminator) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generator가 만든 이미지를 Discriminator가 진짜라고 판단하도록 하는 cost (위조지폐범이 학습해야!)\n",
    "\n",
    "-> 가짜 이미지 판별값 D_gene을 1에 가깝게 만들어야함! => 가짜 이미지를 넣어도 진짜 같다고 판별해야함\n",
    "\n",
    "-> D_gene을 그대로 넣어 이를 손실값으로 사용\n",
    "\n",
    "-> 이 값을 최대화! -> 이를 최대화하면 위조지폐범(Generator) 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN의 학습 = loss_G 와 loss_D 모두 최대화**\n",
    "\n",
    "loss_D와 loss_G : 서로 연관 -> 두 loss가 항상 같이 증가하는 경향을 보이지는 않음! \n",
    "\n",
    "loss_D가 증가 -> loss_G 감소 / loss_G 증가 -> loss_D 감소 => 경쟁관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss 값을 이용해 학습!\n",
    "\n",
    "- loss_D : Discriminator NN에 사용되는 변수들만 사용 -> 최적화\n",
    "\n",
    "- loss_G : Generator NN에 사용되는 변들만 사용 -> 최적화\n",
    "\n",
    "=> loss_D 학습시 Generator 변하지 않음 / loss_G 학습시 Discriminator 변하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list = D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list = G_var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적화 함수 구성\n",
    "\n",
    "loss 최대화 필요! -> optimizer에 사용가능한 함수 : minimize 뿐! -> 최적화하려는 loss_D와 loss_G에 음수 부호 붙여줌!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 학습\n",
    "\n",
    "session 설정과 minibatch를 위한 코드 설정, loss_D와 loss_G의 결과값을 받을 변수 설정 -> minibatch로 학습 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0000 D_loss: -0.6995 G_loss: -1.996\n",
      "Epoch:  0001 D_loss: -0.7599 G_loss: -2.145\n",
      "Epoch:  0002 D_loss: -0.7631 G_loss: -1.936\n",
      "Epoch:  0003 D_loss: -0.6436 G_loss: -1.813\n",
      "Epoch:  0004 D_loss: -0.7147 G_loss: -2.153\n",
      "Epoch:  0005 D_loss: -0.7552 G_loss: -2.136\n",
      "Epoch:  0006 D_loss: -0.6448 G_loss: -2.016\n",
      "Epoch:  0007 D_loss: -0.6783 G_loss: -1.833\n",
      "Epoch:  0008 D_loss: -0.9959 G_loss: -1.854\n",
      "Epoch:  0009 D_loss: -0.7129 G_loss: -1.797\n",
      "Epoch:  0010 D_loss: -0.7516 G_loss: -2.054\n",
      "Epoch:  0011 D_loss: -0.6189 G_loss: -2.0\n",
      "Epoch:  0012 D_loss: -0.6259 G_loss: -1.927\n",
      "Epoch:  0013 D_loss: -0.6345 G_loss: -1.967\n",
      "Epoch:  0014 D_loss: -0.7756 G_loss: -2.078\n",
      "Epoch:  0015 D_loss: -0.6463 G_loss: -1.888\n",
      "Epoch:  0016 D_loss: -0.7917 G_loss: -1.887\n",
      "Epoch:  0017 D_loss: -0.6679 G_loss: -2.052\n",
      "Epoch:  0018 D_loss: -0.7249 G_loss: -2.129\n",
      "Epoch:  0019 D_loss: -0.6273 G_loss: -2.207\n",
      "Epoch:  0020 D_loss: -0.6147 G_loss: -2.277\n",
      "Epoch:  0021 D_loss: -0.7109 G_loss: -1.973\n",
      "Epoch:  0022 D_loss: -0.5671 G_loss: -2.196\n",
      "Epoch:  0023 D_loss: -0.5521 G_loss: -2.258\n",
      "Epoch:  0024 D_loss: -0.5411 G_loss: -2.2\n",
      "Epoch:  0025 D_loss: -0.6726 G_loss: -2.004\n",
      "Epoch:  0026 D_loss: -0.4608 G_loss: -2.527\n",
      "Epoch:  0027 D_loss: -0.7657 G_loss: -2.098\n",
      "Epoch:  0028 D_loss: -0.5949 G_loss: -2.343\n",
      "Epoch:  0029 D_loss: -0.5529 G_loss: -2.262\n",
      "Epoch:  0030 D_loss: -0.744 G_loss: -2.091\n",
      "Epoch:  0031 D_loss: -0.5905 G_loss: -2.068\n",
      "Epoch:  0032 D_loss: -0.6668 G_loss: -2.224\n",
      "Epoch:  0033 D_loss: -0.6773 G_loss: -2.139\n",
      "Epoch:  0034 D_loss: -0.639 G_loss: -2.328\n",
      "Epoch:  0035 D_loss: -0.7474 G_loss: -2.212\n",
      "Epoch:  0036 D_loss: -0.7162 G_loss: -2.286\n",
      "Epoch:  0037 D_loss: -0.5173 G_loss: -2.252\n",
      "Epoch:  0038 D_loss: -0.617 G_loss: -2.161\n",
      "Epoch:  0039 D_loss: -0.6191 G_loss: -2.133\n",
      "Epoch:  0040 D_loss: -0.5453 G_loss: -2.192\n",
      "Epoch:  0041 D_loss: -0.6085 G_loss: -2.189\n",
      "Epoch:  0042 D_loss: -0.6048 G_loss: -2.281\n",
      "Epoch:  0043 D_loss: -0.5557 G_loss: -2.248\n",
      "Epoch:  0044 D_loss: -0.6576 G_loss: -2.298\n",
      "Epoch:  0045 D_loss: -0.5442 G_loss: -2.126\n",
      "Epoch:  0046 D_loss: -0.5857 G_loss: -2.245\n",
      "Epoch:  0047 D_loss: -0.626 G_loss: -2.148\n",
      "Epoch:  0048 D_loss: -0.6046 G_loss: -2.221\n",
      "Epoch:  0049 D_loss: -0.6048 G_loss: -2.306\n",
      "Epoch:  0050 D_loss: -0.5519 G_loss: -2.276\n",
      "Epoch:  0051 D_loss: -0.4688 G_loss: -2.368\n",
      "Epoch:  0052 D_loss: -0.5853 G_loss: -2.414\n",
      "Epoch:  0053 D_loss: -0.7062 G_loss: -2.316\n",
      "Epoch:  0054 D_loss: -0.4713 G_loss: -2.187\n",
      "Epoch:  0055 D_loss: -0.5513 G_loss: -2.541\n",
      "Epoch:  0056 D_loss: -0.4662 G_loss: -2.704\n",
      "Epoch:  0057 D_loss: -0.6379 G_loss: -2.497\n",
      "Epoch:  0058 D_loss: -0.6207 G_loss: -2.248\n",
      "Epoch:  0059 D_loss: -0.5338 G_loss: -2.495\n",
      "Epoch:  0060 D_loss: -0.5745 G_loss: -2.509\n",
      "Epoch:  0061 D_loss: -0.4543 G_loss: -2.221\n",
      "Epoch:  0062 D_loss: -0.673 G_loss: -2.259\n",
      "Epoch:  0063 D_loss: -0.4972 G_loss: -2.463\n",
      "Epoch:  0064 D_loss: -0.4593 G_loss: -2.585\n",
      "Epoch:  0065 D_loss: -0.4466 G_loss: -2.757\n",
      "Epoch:  0066 D_loss: -0.5013 G_loss: -2.419\n",
      "Epoch:  0067 D_loss: -0.6191 G_loss: -2.345\n",
      "Epoch:  0068 D_loss: -0.604 G_loss: -2.375\n",
      "Epoch:  0069 D_loss: -0.6803 G_loss: -2.565\n",
      "Epoch:  0070 D_loss: -0.5453 G_loss: -2.432\n",
      "Epoch:  0071 D_loss: -0.5794 G_loss: -2.299\n",
      "Epoch:  0072 D_loss: -0.5848 G_loss: -2.289\n",
      "Epoch:  0073 D_loss: -0.5119 G_loss: -2.473\n",
      "Epoch:  0074 D_loss: -0.6278 G_loss: -2.553\n",
      "Epoch:  0075 D_loss: -0.4972 G_loss: -2.526\n",
      "Epoch:  0076 D_loss: -0.6144 G_loss: -2.236\n",
      "Epoch:  0077 D_loss: -0.5604 G_loss: -2.303\n",
      "Epoch:  0078 D_loss: -0.6161 G_loss: -2.338\n",
      "Epoch:  0079 D_loss: -0.5203 G_loss: -2.675\n",
      "Epoch:  0080 D_loss: -0.4881 G_loss: -2.665\n",
      "Epoch:  0081 D_loss: -0.4641 G_loss: -2.606\n",
      "Epoch:  0082 D_loss: -0.493 G_loss: -2.785\n",
      "Epoch:  0083 D_loss: -0.5022 G_loss: -2.513\n",
      "Epoch:  0084 D_loss: -0.5744 G_loss: -2.724\n",
      "Epoch:  0085 D_loss: -0.482 G_loss: -2.681\n",
      "Epoch:  0086 D_loss: -0.4902 G_loss: -2.462\n",
      "Epoch:  0087 D_loss: -0.4446 G_loss: -2.954\n",
      "Epoch:  0088 D_loss: -0.5143 G_loss: -2.696\n",
      "Epoch:  0089 D_loss: -0.7887 G_loss: -2.009\n",
      "Epoch:  0090 D_loss: -0.7168 G_loss: -2.491\n",
      "Epoch:  0091 D_loss: -0.392 G_loss: -3.081\n",
      "Epoch:  0092 D_loss: -0.6539 G_loss: -2.594\n",
      "Epoch:  0093 D_loss: -0.4748 G_loss: -2.651\n",
      "Epoch:  0094 D_loss: -0.6113 G_loss: -2.614\n",
      "Epoch:  0095 D_loss: -0.614 G_loss: -2.557\n",
      "Epoch:  0096 D_loss: -0.7183 G_loss: -2.356\n",
      "Epoch:  0097 D_loss: -0.5444 G_loss: -2.595\n",
      "Epoch:  0098 D_loss: -0.471 G_loss: -2.851\n",
      "Epoch:  0099 D_loss: -0.5773 G_loss: -2.508\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        \n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict = {X: batch_xs, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict = {Z: noise})\n",
    "        \n",
    "    print('Epoch: ', '%04d' % epoch,\n",
    "         'D_loss: {:.4}'.format(loss_val_D), \n",
    "         'G_loss: {:.4}'.format(loss_val_G))\n",
    "    \n",
    "    \n",
    "    #확인용 이미지 생성\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict = {Z: noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(1, sample_size, figsize = (sample_size,1))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
    "            \n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches = 'tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator : X값, Generator : Z값(noise) 받음 \n",
    "\n",
    "-> noise 생성해주는 get_noise 함수 사용 => batch_size 만큼 만들고 입력! -> 학습!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 확인용 이미지 생성\n",
    "\n",
    "학습 결과 확인하는 코드 작성!\n",
    "\n",
    "학습이 잘 되는지 0번째, 9번째, 19번째,... 이미지 생성하연 눈으로 직접 확인! -> 결과 확인 코드 loop 안에 작성! \n",
    "\n",
    "1. noize를 만들어 생성자 G에 넣어 결과값 만듦\n",
    "\n",
    "2. 결과값을 28X28 크기의 가짜 이미지로 만들어 sample 폴더에 저장!(sample 폴더는 미리 만들어져 있어야함)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
